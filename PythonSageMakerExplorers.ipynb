{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca3238a",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e0c852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdef2c4",
   "metadata": {},
   "source": [
    "GET data from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e837df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CUSTOMER_KEY       DATE           SHOP_NAME     PRICE\n",
      "0     UDLGCAR 858 2022-10-01  FOOD LOVERS MARKET   8091.60\n",
      "1     GKQQXJR 550 2022-10-01      CHECKERS HYPER    527.57\n",
      "2     UDLGCAR 858 2022-10-01                DRIP   2565.34\n",
      "3     HVRBLTI 309 2022-10-01          WOOLWORTHS    881.93\n",
      "4     UDLGCAR 858 2022-10-02      MR PRICE SPORT  12265.74\n",
      "...           ...        ...                 ...       ...\n",
      "1029   HSUWFZF 75 2023-08-30      CHECKERS HYPER   2361.43\n",
      "1030  GKQQXJR 550 2023-08-30          WOOLWORTHS    435.02\n",
      "1031  HVRBLTI 309 2023-08-30  THE REAL REPAIR CO   3909.05\n",
      "1032  UDLGCAR 858 2023-08-30            COLUMBIA  15537.25\n",
      "1033   HSUWFZF 75 2023-08-30  FOOD LOVERS MARKET  13137.12\n",
      "\n",
      "[1034 rows x 4 columns]\n",
      "                               audio               Bang & Olufsen\n",
      "0                              audio                       Cell C\n",
      "1                              audio                     HP Store\n",
      "2                              audio        Incredible Connection\n",
      "3                              audio                       iStore\n",
      "4                              audio                          MTN\n",
      "..                               ...                          ...\n",
      "131       Sports, Outdoor and Travel                     Footgear\n",
      "132  Supermarkets and Grocery Stores           Food Lovers Market\n",
      "133  Supermarkets and Grocery Stores  Market Liquors Park Meadows\n",
      "134  Supermarkets and Grocery Stores                  Pick 'n Pay\n",
      "135      Tuys, Education and Hobbies                  Smoking Ace\n",
      "\n",
      "[136 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "transaction_list = 'transaction_list_v1.csv'\n",
    "store_list = 'HACK.csv'\n",
    "\n",
    "# Read the CSV file and create a DataFrame\n",
    "df = pd.read_csv(transaction_list)\n",
    "stores_df = pd.read_csv(store_list, encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Convert Date column to date-time object\n",
    "df.DATE = pd.to_datetime(df.DATE)\n",
    "\n",
    "# Now, data_frame contains your CSV data in DataFrame format\n",
    "print(df)\n",
    "print(stores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fceee5c",
   "metadata": {},
   "source": [
    "Some Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04198ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CUSTOMER_KEY       DATE                    SHOP_NAME     PRICE\n",
      "739  HVRBLTI 309 2023-06-02                         TOPS  12760.51\n",
      "740  GKQQXJR 550 2023-06-02                         SPAR    469.83\n",
      "741  AXLVCOE 763 2023-06-02             GRAND PRIX STORE   2812.56\n",
      "742  UDLGCAR 858 2023-06-02                     CHECKERS  17129.00\n",
      "743  AXLVCOE 763 2023-06-03  FLOUR & FAITH HOME INDUSTRY   9326.29\n",
      "..           ...        ...                          ...       ...\n",
      "822  JUXDKJE 784 2023-06-28            BILTONG AND BRAAI    282.44\n",
      "823   OHZPHNE 67 2023-06-28                     CHECKERS    559.27\n",
      "824  GKQQXJR 550 2023-06-28                        REMAX   3334.29\n",
      "825  JUXDKJE 784 2023-06-29                     CHECKERS     72.51\n",
      "826   HSUWFZF 75 2023-06-29           FOOD LOVERS MARKET   1589.40\n",
      "\n",
      "[88 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#SET CUTT_OFF\n",
    "cut_off = pd.to_datetime('2023-06-01')\n",
    "\n",
    "#MAX_DATE\n",
    "max_date = pd.to_datetime('2023-09-30')\n",
    "\n",
    "# Data before cut off\n",
    "observed = df[df['DATE'] < cut_off]\n",
    "\n",
    "#SET LABEL_PERIOD_DAYS\n",
    "label_period_days = 30\n",
    "\n",
    "# Data after cut off\n",
    "future = df[(df['DATE'] > cut_off) & (df['DATE'] < cut_off + pd.Timedelta(label_period_days, unit='D'))]\n",
    "print(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3632e62",
   "metadata": {},
   "source": [
    "Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3643ca9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CUSTOMER_KEY  recency\n",
      "0  AXLVCOE 763       35\n",
      "1  GKQQXJR 550       34\n",
      "2   HSUWFZF 75       32\n",
      "3  HVRBLTI 309       32\n",
      "4  JUXDKJE 784       35\n",
      "5  NSIUPHR 651       37\n",
      "6   OHZPHNE 67       36\n",
      "7  RAYQLJW 475       39\n",
      "8  UDLGCAR 858       33\n",
      "9  ZYVHLTG 995       35\n"
     ]
    }
   ],
   "source": [
    "def customer_recency(data, cut_off, date_column, customer_id_column):\n",
    "\n",
    "    # Copy transactions\n",
    "    cut_off = df.DATE.max()\n",
    "    recency = df[df.DATE < cut_off].copy()\n",
    "\n",
    "    # Group customers by latest transaction\n",
    "    recency = recency.groupby('CUSTOMER_KEY')['DATE'].max()\n",
    "    recency = ((max_date - recency).dt.days).reset_index().rename(columns={'DATE':'recency'})\n",
    "    \n",
    "    return recency\n",
    "\n",
    "print(customer_recency(df, cut_off, 'DATE', 'CUSTOMER_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7adc6ff",
   "metadata": {},
   "source": [
    "Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17212cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CUSTOMER_KEY  frequency\n",
      "0  AXLVCOE 763         11\n",
      "1  GKQQXJR 550         11\n",
      "2   HSUWFZF 75         11\n",
      "3  HVRBLTI 309         11\n",
      "4  JUXDKJE 784          9\n",
      "5  NSIUPHR 651         11\n",
      "6   OHZPHNE 67         11\n",
      "7  RAYQLJW 475         10\n",
      "8  UDLGCAR 858         11\n",
      "9  ZYVHLTG 995         11\n"
     ]
    }
   ],
   "source": [
    "def customer_frequency(data, cut_off, date_column, customer_id_column, value_column, freq='M'):\n",
    "\n",
    "    # Copy transactions\n",
    "    cut_off = df.DATE.max()\n",
    "    frequency = df[df.DATE < cut_off].copy()\n",
    "\n",
    "    # Set date column as index\n",
    "    frequency.set_index('DATE', inplace=True)\n",
    "    frequency.index = pd.DatetimeIndex(frequency.index)\n",
    "\n",
    "    # Group transactions by customer key and by distinct period\n",
    "    # and count transactions in each period\n",
    "    frequency = frequency.groupby(['CUSTOMER_KEY', pd.Grouper(freq=\"M\", level='DATE')]).count()\n",
    "    # (Optional) Only count the number of distinct periods a transaction # occurred. Else, we will be calculating total transactions in each # period instead.\n",
    "\n",
    "    frequency['PRICE'] = 1 # Store all distinct transactions\n",
    "\n",
    "    # Sum transactions\n",
    "    frequency = frequency.groupby('CUSTOMER_KEY').sum().reset_index().rename(columns={'PRICE' : 'frequency'})\n",
    "    return frequency.drop(['SHOP_NAME'], axis=1)\n",
    "print(customer_frequency(df, cut_off, 'DATE', 'CUSTOMER_KEY', 'PRICE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0a8343",
   "metadata": {},
   "source": [
    "Monetary Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0ecff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CUSTOMER_KEY         value\n",
      "0  AXLVCOE 763   2679.912794\n",
      "1  GKQQXJR 550   7499.385786\n",
      "2   HSUWFZF 75   5913.899764\n",
      "3  HVRBLTI 309   7261.294953\n",
      "4  JUXDKJE 784   1413.183243\n",
      "5  NSIUPHR 651   8698.317262\n",
      "6   OHZPHNE 67   1110.301346\n",
      "7  RAYQLJW 475   1018.598667\n",
      "8  UDLGCAR 858  11174.763527\n",
      "9  ZYVHLTG 995   8533.245952\n"
     ]
    }
   ],
   "source": [
    "def customer_value(data, cut_off, date_column, customer_id_column, value_column):\n",
    "\n",
    "    # Copy transactions\n",
    "    cut_off = df.DATE.max()\n",
    "    value = df[df.DATE < cut_off].copy()\n",
    "\n",
    "    # Set date column as index\n",
    "    value.set_index('DATE', inplace=True)\n",
    "    value.index = pd.DatetimeIndex(value.index)\n",
    "\n",
    "    # Get mean or total sales amount for each customer\n",
    "    value = value.groupby('CUSTOMER_KEY')['PRICE'].mean().reset_index().rename(columns={'PRICE' : 'value'})\n",
    "\n",
    "    return value\n",
    "print(customer_value(df, cut_off, 'DATE', 'CUSTOMER_KEY', 'PRICE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d67fe8",
   "metadata": {},
   "source": [
    "Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67585a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CUSTOMER_KEY       DATE  age\n",
      "0  AXLVCOE 763 2022-10-04  330\n",
      "1  GKQQXJR 550 2022-10-01  333\n",
      "2   HSUWFZF 75 2022-10-03  331\n",
      "3  HVRBLTI 309 2022-10-01  333\n",
      "4  JUXDKJE 784 2022-10-05  329\n",
      "5  NSIUPHR 651 2022-10-02  332\n",
      "6   OHZPHNE 67 2022-10-03  331\n",
      "7  RAYQLJW 475 2022-10-08  326\n",
      "8  UDLGCAR 858 2022-10-01  333\n",
      "9  ZYVHLTG 995 2022-10-03  331\n"
     ]
    }
   ],
   "source": [
    "def customer_age(data, cut_off, date_column, customer_id_column):\n",
    "    # Copy transactions\n",
    "    cut_off = df.DATE.max()\n",
    "    age = df[df.DATE < cut_off].copy()\n",
    "\n",
    "    # Get date of first transaction\n",
    "    first_purchase = age.groupby('CUSTOMER_KEY')['DATE'].min().reset_index()\n",
    "\n",
    "    # Get number of days between cut off and first transaction\n",
    "    first_purchase['age'] = (cut_off - first_purchase['DATE']).dt.days\n",
    "\n",
    "    return first_purchase\n",
    "print(customer_age(df, cut_off, 'DATE', 'CUSTOMER_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94167928",
   "metadata": {},
   "source": [
    "Combine all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd469deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_rfm(data, cut_off, date_column, customer_id_column, value_column, freq='M'):\n",
    "    cut_off = pd.to_datetime(cut_off)\n",
    "  \n",
    "    # Compute Recency\n",
    "    recency = customer_recency(data, cut_off, date_column, customer_id_column)\n",
    "\n",
    "    # Compute Frequency\n",
    "    frequency = customer_frequency(data, cut_off, date_column, customer_id_column, value_column, freq=freq)\n",
    "\n",
    "    # Compute average value\n",
    "    monetary_value = customer_value(data, cut_off, date_column, customer_id_column, value_column)\n",
    "\n",
    "    # Compute age\n",
    "    age = customer_age(data, cut_off, date_column, customer_id_column)\n",
    "\n",
    "    # Merge all columns\n",
    "    return recency.merge(frequency, on=customer_id_column).merge(age, on=customer_id_column).merge(monetary_value, on=customer_id_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b65385d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CUSTOMER_KEY  recency  frequency       DATE  age         value\n",
      "0  AXLVCOE 763       35         11 2022-10-04  330   2679.912794\n",
      "1  GKQQXJR 550       34         11 2022-10-01  333   7499.385786\n",
      "2   HSUWFZF 75       32         11 2022-10-03  331   5913.899764\n",
      "3  HVRBLTI 309       32         11 2022-10-01  333   7261.294953\n",
      "4  JUXDKJE 784       35          9 2022-10-05  329   1413.183243\n",
      "5  NSIUPHR 651       37         11 2022-10-02  332   8698.317262\n",
      "6   OHZPHNE 67       36         11 2022-10-03  331   1110.301346\n",
      "7  RAYQLJW 475       39         10 2022-10-08  326   1018.598667\n",
      "8  UDLGCAR 858       33         11 2022-10-01  333  11174.763527\n",
      "9  ZYVHLTG 995       35         11 2022-10-03  331   8533.245952\n"
     ]
    }
   ],
   "source": [
    "a = customer_rfm(df, cut_off, 'DATE', 'CUSTOMER_KEY', 'PRICE')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d63e691",
   "metadata": {},
   "source": [
    "CHURN FUTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b123c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_churn_labels(future):\n",
    "    future['DidBuy'] = 1\n",
    "    return future[['CUSTOMER_KEY', 'DidBuy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1562690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CUSTOMER_KEY  DidBuy\n",
      "0  AXLVCOE 763       1\n",
      "1  GKQQXJR 550       1\n",
      "2   HSUWFZF 75       1\n",
      "3  HVRBLTI 309       1\n",
      "4  JUXDKJE 784       1\n",
      "5  NSIUPHR 651       1\n",
      "6   OHZPHNE 67       1\n",
      "7  RAYQLJW 475       1\n",
      "8  UDLGCAR 858       1\n",
      "9  ZYVHLTG 995       1\n"
     ]
    }
   ],
   "source": [
    "b = generate_churn_labels(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d0a4c",
   "metadata": {},
   "source": [
    "Recursive RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26df5a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12818/3333728349.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future['DidBuy'] = 1\n",
      "/tmp/ipykernel_12818/3333728349.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future['DidBuy'] = 1\n",
      "/tmp/ipykernel_12818/3333728349.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future['DidBuy'] = 1\n",
      "/tmp/ipykernel_12818/3333728349.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future['DidBuy'] = 1\n",
      "/tmp/ipykernel_12818/3333728349.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future['DidBuy'] = 1\n",
      "/tmp/ipykernel_12818/3333728349.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future['DidBuy'] = 1\n",
      "/tmp/ipykernel_12818/3333728349.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future['DidBuy'] = 1\n",
      "/tmp/ipykernel_12818/3333728349.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future['DidBuy'] = 1\n",
      "/tmp/ipykernel_12818/3333728349.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future['DidBuy'] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CUSTOMER_KEY  recency  frequency       DATE  age        value  DidBuy\n",
      "0    AXLVCOE 763       35         11 2022-10-04  330  2679.912794     1.0\n",
      "1    AXLVCOE 763       35         11 2022-10-04  330  2679.912794     1.0\n",
      "2    AXLVCOE 763       35         11 2022-10-04  330  2679.912794     1.0\n",
      "3    AXLVCOE 763       35         11 2022-10-04  330  2679.912794     1.0\n",
      "4    GKQQXJR 550       34         11 2022-10-01  333  7499.385786     1.0\n",
      "..           ...      ...        ...        ...  ...          ...     ...\n",
      "105  ZYVHLTG 995       35         11 2022-10-03  331  8533.245952     1.0\n",
      "106  ZYVHLTG 995       35         11 2022-10-03  331  8533.245952     1.0\n",
      "107  ZYVHLTG 995       35         11 2022-10-03  331  8533.245952     1.0\n",
      "108  ZYVHLTG 995       35         11 2022-10-03  331  8533.245952     1.0\n",
      "109  ZYVHLTG 995       35         11 2022-10-03  331  8533.245952     1.0\n",
      "\n",
      "[926 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12818/3333728349.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future['DidBuy'] = 1\n"
     ]
    }
   ],
   "source": [
    "def recursive_rfm(data, date_col, id_col, value_col, freq='M', start_length=30, label_period_days=30):\n",
    "    # Resultant list of datasets\n",
    "    dset_list = []\n",
    "    # Get start and end dates of dataset\n",
    "    start_date = data[date_col].min() + pd.Timedelta(start_length, unit=\"D\")\n",
    "    end_date = data[date_col].max() - pd.Timedelta(label_period_days, unit=\"D\")\n",
    "    # Get dates at desired interval\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='M')\n",
    "    data[date_col] = pd.to_datetime(data[date_col])\n",
    "    for cut_off in dates:\n",
    "        # split by observed / future\n",
    "        observed = data[data[date_col] < cut_off]\n",
    "        future = data[(data[date_col] > cut_off) & (data[date_col] < cut_off + pd.Timedelta(label_period_days,  unit='D'))]\n",
    "        # Get relevant columns\n",
    "        rfm_columns = [date_col, id_col, value_col]\n",
    "        _observed = observed[rfm_columns]\n",
    "        # Compute features from observed\n",
    "        rfm_features = customer_rfm(_observed, cut_off, date_col, id_col, value_col)\n",
    "        # Set label for everyone who bought in 'future' as 1'\n",
    "        labels = generate_churn_labels(future)\n",
    "        # Outer join features with labels to ensure customers \n",
    "        # not in observed are still recorded with a label of 0\n",
    "        dset = rfm_features.merge(labels, on=id_col, how='outer').fillna(0)\n",
    "        dset_list.append(dset)\n",
    "    # Concatenate all datasets\n",
    "    full_dataset = pd.concat(dset_list, axis=0)\n",
    "    res = full_dataset[full_dataset.recency != 0].dropna(axis=1, how='any')\n",
    "    return res\n",
    "\n",
    "rec_df = recursive_rfm(df, 'DATE', 'CUSTOMER_KEY', 'PRICE')\n",
    "print(rec_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70d475",
   "metadata": {},
   "source": [
    "Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a278bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rec_df = rec_df.sample(frac=1) # Shuffle\n",
    "\n",
    "# Set X and y\n",
    "X = rec_df[['recency', 'frequency', 'value', 'age']]\n",
    "y = rec_df[['DidBuy']].values.reshape(-1)\n",
    "\n",
    "# Set test ratio and perform train / test split\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, shuffle=True)\n",
    "\n",
    "rec_df.DidBuy.value_counts()\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and fit model on train dataset\n",
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Fit on over-sampled data as well\n",
    "#rf_over = RandomForestRegressor().fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12700f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9959, Test Acc: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00       186\n",
      "\n",
      "    accuracy                           1.00       186\n",
      "   macro avg       1.00      1.00      1.00       186\n",
      "weighted avg       1.00      1.00      1.00       186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create Dataframe and populate with predictions and actuals\n",
    "# Train set\n",
    "predictions = pd.DataFrame()\n",
    "predictions['true'] = y_train\n",
    "predictions['preds'] = rf.predict(X_train)\n",
    "\n",
    "# Test set\n",
    "predictions_test = pd.DataFrame()\n",
    "predictions_test['true'] = y_test\n",
    "predictions_test['preds'] = rf.predict(X_test)\n",
    "\n",
    "# Compute error\n",
    "train_acc = accuracy_score(predictions.true, predictions.preds)\n",
    "test_acc = accuracy_score(predictions_test.true, predictions_test.preds)\n",
    "print(f\"Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "print(classification_report(predictions_test.true, predictions_test.preds))\n",
    "\n",
    "#WE can use predict_proba(X), please check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42ad22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the spaCy NLP model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Sample list of stores and products\n",
    "#stores = [\"Apple\", \"ABSA Bank\", \"Fruit And Veg\"]\n",
    "\n",
    "def all_lower(my_list):\n",
    "    return [x.lower() for x in my_list]\n",
    "\n",
    "res = []\n",
    "for ele in all_lower(df['SHOP_NAME'].unique()):\n",
    "    if ele.strip():\n",
    "        res.append(ele)\n",
    "        \n",
    "stores = res\n",
    "products = ['ABSA Islamic Cheque', 'Credit card', 'Cheque', 'Contractual saving', 'Estates', 'Fixed deposit', 'Financial Management', \n",
    "            'Unit Linked products', 'Loan', 'Mortgage Loan', 'Notice fixed deposit', 'Participation bonds', 'Portfolios', \n",
    "            'Saving', 'Term deposit', 'Trusts', 'Unit Trusts', 'Wills', 'ABSA Life Assurance', 'Car Short Term Insurance', \n",
    "            'ABSA Investment Management', 'Local Documentary Products', 'Broker Budget', 'Absa Life Mulpas', 'Credit card', \n",
    "            'General ledger', 'Merchant', 'Ping It', 'Commercial Property Finance', 'Absa Working Capital Solutions', 'Pension Backed Loan']\n",
    "\n",
    "# Function to associate a store with a product using NLP\n",
    "def associate_store_with_product(store, products):\n",
    "    max_similarity = 0\n",
    "    associated_product = ''\n",
    "    for product in products:\n",
    "        # Calculate similarity between store and product using spaCy similarity score\n",
    "        similarity = nlp(store).similarity(nlp(product))\n",
    "        print(product)\n",
    "        print(similarity)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            associated_product = product\n",
    "            print(associated_product)\n",
    "    print (associated_product)\n",
    "    return associated_product\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23a4f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "115c35c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSA Islamic Cheque\n",
      "0.0363678700665364\n",
      "ABSA Islamic Cheque\n",
      "Credit card\n",
      "0.1788700916871432\n",
      "Credit card\n",
      "Cheque\n",
      "0.07323286001298203\n",
      "Contractual saving\n",
      "0.05937706171940165\n",
      "Estates\n",
      "0.1207387208986501\n",
      "Fixed deposit\n",
      "0.09268214663695745\n",
      "Financial Management\n",
      "0.255889893509982\n",
      "Financial Management\n",
      "Unit Linked products\n",
      "0.2567114769990405\n",
      "Unit Linked products\n",
      "Loan\n",
      "0.12150045720368878\n",
      "Mortgage Loan\n",
      "0.14484028104294022\n",
      "Notice fixed deposit\n",
      "0.06560691961134725\n",
      "Participation bonds\n",
      "0.11341519594992991\n",
      "Portfolios\n",
      "0.27080125996574994\n",
      "Portfolios\n",
      "Saving\n",
      "-0.019728954868473716\n",
      "Term deposit\n",
      "0.05901040844777952\n",
      "Trusts\n",
      "0.07460970584882205\n",
      "Unit Trusts\n",
      "0.162082848924737\n",
      "Wills\n",
      "0.015863910579552915\n",
      "ABSA Life Assurance\n",
      "0.15138844220912598\n",
      "Car Short Term Insurance\n",
      "0.3365613857454878\n",
      "Car Short Term Insurance\n",
      "ABSA Investment Management\n",
      "0.25030723826501816\n",
      "Local Documentary Products\n",
      "0.19846384913358558\n",
      "Broker Budget\n",
      "0.2738393504099854\n",
      "Absa Life Mulpas\n",
      "0.06767105593921531\n",
      "Credit card\n",
      "0.1788700916871432\n",
      "General ledger\n",
      "0.026817167574884122\n",
      "Merchant\n",
      "0.029212770332735203\n",
      "Ping It\n",
      "0.061239581427185726\n",
      "Commercial Property Finance\n",
      "0.2724463017292312\n",
      "Absa Working Capital Solutions\n",
      "0.2572253807999427\n",
      "Pension Backed Loan\n",
      "0.15768634354006564\n",
      "Car Short Term Insurance\n",
      "The product associated with Audi is: Car Short Term Insurance\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "store_to_associate = \"Audi\"  # Replace this with the store you want to associate\n",
    "associated_product = associate_store_with_product(store_to_associate, products)\n",
    "\n",
    "print(f\"The product associated with {store_to_associate} is: {associated_product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9b06c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fda853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
